{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS388_FP_Origin.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49LQqe2el6M1"
      },
      "source": [
        "# 0. Check your runtime - connect to GPU!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCIW3XX0l98H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30707e2-0753-45d2-b783-18ae0590a81c"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Apr 27 04:44:28 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Et-M-FhTXK"
      },
      "source": [
        "## Note: Google colab does not offer permanent storage.  You can mount your drive if you so desire\n",
        "# 1. Download your code from Github! Be sure to replace repo_name with your fork"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUW_eaY4ge35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483381a8-0ae0-43b2-8578-e9f67291143e"
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "repo_name = \"LucyErJunJun/nlp-qa-finalproj\"\n",
        "# Example\n",
        "# repo_name = \"gregdurrett/nlp-qa-finalproj.git\"\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/{2}'.format(user, password, repo_name)\n",
        "\n",
        "!{cmd_string}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: LucyErJunJun\n",
            "Password: ··········\n",
            "Cloning into 'nlp-qa-finalproj'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 47 (delta 7), reused 11 (delta 4), pack-reused 31\u001b[K\n",
            "Unpacking objects: 100% (47/47), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag8b9dSJhmp_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42457ac0-39db-4c20-bbde-2bf40905f4b3"
      },
      "source": [
        "%cd nlp-qa-finalproj/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/nlp-qa-finalproj\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MClUwlARhvsx"
      },
      "source": [
        "# 2. Download the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_wwMma5hvPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aeffdf0-3f01-4a13-afea-c158eda20a5f"
      },
      "source": [
        "!bash ./setup.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Illegal option -s\n",
            "Usage: /usr/bin/which [-a] args\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 26.3M  100 26.3M    0     0  64.7M      0 --:--:-- --:--:-- --:--:-- 64.5M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 53.8M  100 53.8M    0     0  80.3M      0 --:--:-- --:--:-- --:--:-- 80.3M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 3392k  100 3392k    0     0  14.7M      0 --:--:-- --:--:-- --:--:-- 14.6M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 3069k  100 3069k    0     0  12.2M      0 --:--:-- --:--:-- --:--:-- 12.3M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2603k  100 2603k    0     0  1502k      0  0:00:01  0:00:01 --:--:-- 1501k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   371  100   371    0     0   2650      0 --:--:-- --:--:-- --:--:--  2650\n",
            "100 1075k  100 1075k    0     0  1624k      0 --:--:-- --:--:-- --:--:-- 1624k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  822M  100  822M    0     0  4744k      0  0:02:57  0:02:57 --:--:-- 3342k\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "  inflating: glove.6B.50d.txt        \n",
            "\n",
            "done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TYpACBTh6hy"
      },
      "source": [
        "# 3. Train and Eval your model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJvWnC2ciaoD"
      },
      "source": [
        "## Get any updates to your code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJh_Yq49h6C2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf262b71-bf6a-403d-f111-6321a7b9d426"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_lLvgwFixQ6"
      },
      "source": [
        "## Train your model from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRhrd9YmiEwf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54cf679-8dd6-4a3d-d7a5-a1704b8709a7"
      },
      "source": [
        " !python3 main.py \\\n",
        "    --use_gpu \\\n",
        "    --model \"baseline\" \\\n",
        "    --model_path \"squad_model_origin.pt\" \\\n",
        "    --train_path \"datasets/squad_train.jsonl.gz\" \\\n",
        "    --dev_path \"datasets/squad_dev.jsonl.gz\" \\\n",
        "    --output_path \"squad_predictions_origin.txt\" \\\n",
        "    --hidden_dim 256 \\\n",
        "    --bidirectional \\\n",
        "    --do_train \\\n",
        "    --do_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "using arguments:\n",
            "{'batch_size': 64,\n",
            " 'bidirectional': True,\n",
            " 'dev_path': 'datasets/squad_dev.jsonl.gz',\n",
            " 'device': None,\n",
            " 'do_test': True,\n",
            " 'do_train': True,\n",
            " 'dropout': 0.0,\n",
            " 'early_stop': 3,\n",
            " 'embedding_dim': 300,\n",
            " 'embedding_path': 'glove/glove.6B.300d.txt',\n",
            " 'epochs': 10,\n",
            " 'grad_clip': 0.5,\n",
            " 'hidden_dim': 256,\n",
            " 'learning_rate': 0.001,\n",
            " 'max_context_length': 384,\n",
            " 'max_question_length': 64,\n",
            " 'model': 'baseline',\n",
            " 'model_path': 'squad_model_origin.pt',\n",
            " 'output_path': 'squad_predictions_origin.txt',\n",
            " 'rnn_cell_type': 'lstm',\n",
            " 'shuffle_examples': False,\n",
            " 'train_path': 'datasets/squad_train.jsonl.gz',\n",
            " 'use_gpu': True,\n",
            " 'vocab_size': 50000,\n",
            " 'weight_decay': 0.0}\n",
            "\n",
            "vocab words = 50002\n",
            "train samples = 86588\n",
            "dev samples = 10507\n",
            "\n",
            "tcmalloc: large alloc 1181990912 bytes == 0x557f90224000 @  0x7f77e226c2a4 0x557f31b9b06c 0x557f31b3ebe0 0x557f31c5039c 0x557f31c4f857 0x557f31c502a8 0x557f31c4eaac 0x557f31b406a2 0x557f31b9e00c 0x557f31b9dde0 0x557f31c12244 0x557f31b9f69a 0x557f31c0da45 0x557f31b9f69a 0x557f31c11e50 0x557f31b9f69a 0x557f31c0da45 0x557f31c0cb0e 0x557f31c0c813 0x557f31cd6592 0x557f31cd690d 0x557f31cd67b6 0x557f31cae103 0x557f31caddac 0x7f77e1055bf7 0x557f31cadc8a\n",
            "using pre-trained embeddings from 'glove/glove.6B.300d.txt'\n",
            "initialized 45801/50002 embeddings (91.6%)\n",
            "\n",
            "using model 'baseline' (18516693 params)\n",
            "BaselineReader(\n",
            "  (embedding): Embedding(50002, 300)\n",
            "  (aligned_att): AlignedAttention(\n",
            "    (linear): Linear(in_features=300, out_features=300, bias=True)\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (passage_rnn): LSTM(600, 256, batch_first=True, bidirectional=True)\n",
            "  (question_rnn): LSTM(300, 256, batch_first=True, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            "  (question_att): SpanAttention(\n",
            "    (linear): Linear(in_features=512, out_features=1, bias=True)\n",
            "  )\n",
            "  (start_output): BilinearOutput(\n",
            "    (linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "  )\n",
            "  (end_output): BilinearOutput(\n",
            "    (linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "epoch = 1 | train loss = 2.276799 | eval loss = 2.110355 | saving model!\n",
            "epoch = 2 | train loss = 1.502468 | eval loss = 1.976240 | saving model!\n",
            "epoch = 3 | train loss = 1.083441 | eval loss = 2.223849 | \n",
            "epoch = 4 | train loss = 0.745848 | eval loss = 2.666744 | \n",
            "epoch = 5 | train loss = 0.509939 | eval loss = 3.219479 | \n",
            "no improvement after 3 epochs. early stopping...\n",
            "\n",
            "                                    \n",
            "predictions written to 'squad_predictions_origin.txt'\n",
            "compute EM/F1 with: 'python3 evaluate.py --dataset_path datasets/squad_dev.jsonl.gz --output_path squad_predictions_origin.txt'\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3tvL__ni_Ih"
      },
      "source": [
        "## Evaluate it now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osVM5y5AjFTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83f2ba8e-63fa-44f1-b03a-0b57ad127fcd"
      },
      "source": [
        "!python3 evaluate.py \\\n",
        "    --dataset_path \"datasets/squad_dev.jsonl.gz\" \\\n",
        "    --output_path \"squad_predictions_origin.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'EM': 48.98, 'F1': 61.33}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL1BH7p1h-u6"
      },
      "source": [
        "## Don't forget to download it when you are done!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8NpfGltjI7G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "561cc383-a794-47fc-aee9-3b071a6179e9"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('squad_model_origin.pt')\n",
        "files.download('squad_predictions_origin.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2e29fb76-cadd-48ee-97d3-277d865c72e1\", \"squad_model_origin.pt\", 74072722)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_da510ecc-d61d-421b-93f4-32b95ce9e278\", \"squad_predictions_origin.txt\", 819502)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg8SxENJhuLq"
      },
      "source": [
        "tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P70XSCmSiRcQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}